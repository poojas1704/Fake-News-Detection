{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cad6df3",
   "metadata": {},
   "source": [
    "## Section 3: Fake News and Naive Bayes (20 pts)\n",
    "\n",
    "For this section, I am going to apply Naive Bayes to a data set used in a recent [Kaggle competition](https://www.kaggle.com/competitions/fake-news/data). The goal of of this project is to build a classifer that could predict whether a news story is fake or true. \n",
    "\n",
    "The dataset includes two files: (1) a training data file with labels that includes an id, author, title, and text, (2) the test data set with the same features as the training data file except with no label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c8d404f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, cut_tree\n",
    "import seaborn as sns\n",
    "import re, string #import packages for regex replacement\n",
    "from nltk.tokenize import TweetTokenizer # import tokenizer from nltk\n",
    "import nltk # download the list of stopwords from nltk if you have not done this before\n",
    "from nltk.corpus import stopwords # import stopwords\n",
    "stopeng = set(stopwords.words('english')) #set language\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import *\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fa921b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Jackie Mason: Hollywood Would Love Trump if He...</td>\n",
       "      <td>Daniel Nussbaum</td>\n",
       "      <td>In these trying times, Jackie Mason is the Voi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Life: Life Of Luxury: Elton John’s 6 Favorite ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ever wonder how Britain’s most iconic pop pian...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Benoît Hamon Wins French Socialist Party’s Pre...</td>\n",
       "      <td>Alissa J. Rubin</td>\n",
       "      <td>PARIS  —   France chose an idealistic, traditi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Excerpts From a Draft Script for Donald Trump’...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Donald J. Trump is scheduled to make a highly ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>A Back-Channel Plan for Ukraine and Russia, Co...</td>\n",
       "      <td>Megan Twohey and Scott Shane</td>\n",
       "      <td>A week before Michael T. Flynn resigned as nat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                              title  \\\n",
       "0  0  House Dem Aide: We Didn’t Even See Comey’s Let...   \n",
       "1  1  FLYNN: Hillary Clinton, Big Woman on Campus - ...   \n",
       "2  2                  Why the Truth Might Get You Fired   \n",
       "3  3  15 Civilians Killed In Single US Airstrike Hav...   \n",
       "4  4  Iranian woman jailed for fictional unpublished...   \n",
       "5  5  Jackie Mason: Hollywood Would Love Trump if He...   \n",
       "6  6  Life: Life Of Luxury: Elton John’s 6 Favorite ...   \n",
       "7  7  Benoît Hamon Wins French Socialist Party’s Pre...   \n",
       "8  8  Excerpts From a Draft Script for Donald Trump’...   \n",
       "9  9  A Back-Channel Plan for Ukraine and Russia, Co...   \n",
       "\n",
       "                         author  \\\n",
       "0                 Darrell Lucus   \n",
       "1               Daniel J. Flynn   \n",
       "2            Consortiumnews.com   \n",
       "3               Jessica Purkiss   \n",
       "4                Howard Portnoy   \n",
       "5               Daniel Nussbaum   \n",
       "6                           NaN   \n",
       "7               Alissa J. Rubin   \n",
       "8                           NaN   \n",
       "9  Megan Twohey and Scott Shane   \n",
       "\n",
       "                                                text label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...     1  \n",
       "1  Ever get the feeling your life circles the rou...     0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...     1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...     1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...     1  \n",
       "5  In these trying times, Jackie Mason is the Voi...     0  \n",
       "6  Ever wonder how Britain’s most iconic pop pian...     1  \n",
       "7  PARIS  —   France chose an idealistic, traditi...     0  \n",
       "8  Donald J. Trump is scheduled to make a highly ...     0  \n",
       "9  A week before Michael T. Flynn resigned as nat...     0  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the training data\n",
    "train_df = pd.read_csv('train.csv', dtype='str')\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cf8357",
   "metadata": {},
   "source": [
    "#### For the above problem, I think the most relevant features are author, title, and text. The author could be a good predictor because it is possible for a author (or source) to be known for publishing untrue stories. Additionally, Title and Text features could help the machine determine some commonly used words in the untrue stories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7ec1a9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id           0\n",
      "title      558\n",
      "author    1957\n",
      "text        39\n",
      "label        0\n",
      "dtype: int64\n",
      "id        0\n",
      "title     0\n",
      "author    0\n",
      "text      0\n",
      "label     0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jackie Mason: Hollywood Would Love Trump if He...</td>\n",
       "      <td>Daniel Nussbaum</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Benoît Hamon Wins French Socialist Party’s Pre...</td>\n",
       "      <td>Alissa J. Rubin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A Back-Channel Plan for Ukraine and Russia, Co...</td>\n",
       "      <td>Megan Twohey and Scott Shane</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Obama’s Organizing for Action Partners with So...</td>\n",
       "      <td>Aaron Klein</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BBC Comedy Sketch \"Real Housewives of ISIS\" Ca...</td>\n",
       "      <td>Chris Tomlinson</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0   House Dem Aide: We Didn’t Even See Comey’s Let...   \n",
       "1   FLYNN: Hillary Clinton, Big Woman on Campus - ...   \n",
       "2                   Why the Truth Might Get You Fired   \n",
       "3   15 Civilians Killed In Single US Airstrike Hav...   \n",
       "4   Iranian woman jailed for fictional unpublished...   \n",
       "5   Jackie Mason: Hollywood Would Love Trump if He...   \n",
       "7   Benoît Hamon Wins French Socialist Party’s Pre...   \n",
       "9   A Back-Channel Plan for Ukraine and Russia, Co...   \n",
       "10  Obama’s Organizing for Action Partners with So...   \n",
       "11  BBC Comedy Sketch \"Real Housewives of ISIS\" Ca...   \n",
       "\n",
       "                          author label  \n",
       "0                  Darrell Lucus     1  \n",
       "1                Daniel J. Flynn     0  \n",
       "2             Consortiumnews.com     1  \n",
       "3                Jessica Purkiss     1  \n",
       "4                 Howard Portnoy     1  \n",
       "5                Daniel Nussbaum     0  \n",
       "7                Alissa J. Rubin     0  \n",
       "9   Megan Twohey and Scott Shane     0  \n",
       "10                   Aaron Klein     0  \n",
       "11               Chris Tomlinson     0  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract features\n",
    "\n",
    "print(train_df.isnull().sum())\n",
    "#train_df['title'].fillna('',inplace=True)\n",
    "#train_df['author'].fillna('',inplace=True)\n",
    "train_df = train_df.dropna(axis=0)\n",
    "print(train_df.isnull().sum())\n",
    "\n",
    "train_df = train_df[['title', 'author', 'label']]\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b3f817e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why the Truth Might Get You Fired Consortiumne...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jackie Mason: Hollywood Would Love Trump if He...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Benoît Hamon Wins French Socialist Party’s Pre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A Back-Channel Plan for Ukraine and Russia, Co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Obama’s Organizing for Action Partners with So...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BBC Comedy Sketch \"Real Housewives of ISIS\" Ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              feature label\n",
       "0   House Dem Aide: We Didn’t Even See Comey’s Let...     1\n",
       "1   FLYNN: Hillary Clinton, Big Woman on Campus - ...     0\n",
       "2   Why the Truth Might Get You Fired Consortiumne...     1\n",
       "3   15 Civilians Killed In Single US Airstrike Hav...     1\n",
       "4   Iranian woman jailed for fictional unpublished...     1\n",
       "5   Jackie Mason: Hollywood Would Love Trump if He...     0\n",
       "7   Benoît Hamon Wins French Socialist Party’s Pre...     0\n",
       "9   A Back-Channel Plan for Ukraine and Russia, Co...     0\n",
       "10  Obama’s Organizing for Action Partners with So...     0\n",
       "11  BBC Comedy Sketch \"Real Housewives of ISIS\" Ca...     0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining title and author to create one input feature for the model \n",
    "\n",
    "train_df_updated = pd.DataFrame()\n",
    "train_df_updated['feature'] = train_df['title'] + \" \" + train_df['author']\n",
    "train_df_updated['label'] = train_df['label']\n",
    "\n",
    "train_df_updated.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "517dc4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for removing punctuations and cleaning the data\n",
    "\n",
    "def clean_text_round(row):\n",
    "    row = row.lower()\n",
    "    row = re.sub(r\"[^\\w\\s]\", '', row)\n",
    "    row = re.sub('\\'', '', row) #remove commas\n",
    "    row = re.sub(',', '', row) #remove commas\n",
    "    row = re.sub('\\n', '', row) # remove carrot inserts from collection <---- new operation\n",
    "    row = re.sub('-', '', row)\n",
    "    row = re.sub('\\?', '', row)\n",
    "    row = re.sub('\\.', '', row)\n",
    "    row = re.sub('\\'', '', row)\n",
    "    row = re.sub('\\\"', '', row)\n",
    "    row = re.sub('#', '', row)\n",
    "    return row\n",
    "\n",
    "clean = lambda x: clean_text_round(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ae48d3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>house dem aide we didnt even see comeys letter...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flynn hillary clinton big woman on campus  bre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why the truth might get you fired consortiumne...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15 civilians killed in single us airstrike hav...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature label\n",
       "0  house dem aide we didnt even see comeys letter...     1\n",
       "1  flynn hillary clinton big woman on campus  bre...     0\n",
       "2  why the truth might get you fired consortiumne...     1\n",
       "3  15 civilians killed in single us airstrike hav...     1\n",
       "4  iranian woman jailed for fictional unpublished...     1"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the function above across each row of the text column\n",
    "\n",
    "train_df_updated.loc[:, 'feature'] = train_df_updated['feature'].apply(clean)\n",
    "train_df_updated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "21d1d502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tokenizer from nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tweet_tokenizer = TweetTokenizer() \n",
    "\n",
    "# define a function that we can apply over our data\n",
    "\n",
    "def tweet_tokenize(row):\n",
    "    row = tweet_tokenizer.tokenize(row)\n",
    "    return row\n",
    "\n",
    "tokenized = lambda x: tweet_tokenize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c02249b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[house, dem, aide, we, didnt, even, see, comey...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[flynn, hillary, clinton, big, woman, on, camp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[why, the, truth, might, get, you, fired, cons...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[15, civilians, killed, in, single, us, airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[iranian, woman, jailed, for, fictional, unpub...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature label\n",
       "0  [house, dem, aide, we, didnt, even, see, comey...     1\n",
       "1  [flynn, hillary, clinton, big, woman, on, camp...     0\n",
       "2  [why, the, truth, might, get, you, fired, cons...     1\n",
       "3  [15, civilians, killed, in, single, us, airstr...     1\n",
       "4  [iranian, woman, jailed, for, fictional, unpub...     1"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the tweet_tokenize function on the train data\n",
    "\n",
    "train_df_updated.loc[:, 'feature'] = train_df_updated['feature'].apply(tokenized)\n",
    "train_df_updated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "64d5a6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('stopwords') # download the list of stopwords from nltk if you have not done this before\n",
    "from nltk.corpus import stopwords # import stopwords\n",
    "\n",
    "stopeng = set(stopwords.words('english')) #set language\n",
    "\n",
    "#define a function to remove stopwords\n",
    "def remove_stopwords(row):\n",
    "    row = [w for w in row if w not in stopeng]\n",
    "    return row\n",
    "\n",
    "no_stopwords = lambda x: remove_stopwords(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e773aec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[house, dem, aide, didnt, even, see, comeys, l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[flynn, hillary, clinton, big, woman, campus, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[truth, might, get, fired, consortiumnewscom]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[15, civilians, killed, single, us, airstrike,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[iranian, woman, jailed, fictional, unpublishe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature label\n",
       "0  [house, dem, aide, didnt, even, see, comeys, l...     1\n",
       "1  [flynn, hillary, clinton, big, woman, campus, ...     0\n",
       "2      [truth, might, get, fired, consortiumnewscom]     1\n",
       "3  [15, civilians, killed, single, us, airstrike,...     1\n",
       "4  [iranian, woman, jailed, fictional, unpublishe...     1"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply function to remove stopwords on the train data\n",
    "\n",
    "train_df_updated.loc[:, 'feature'] = train_df_updated['feature'].apply(no_stopwords)\n",
    "train_df_updated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8eac1a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('wordnet') # you may need to run these depending on your setup\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lmtzr = WordNetLemmatizer()\n",
    "\n",
    "# define function to lemmatize\n",
    "def lemmatize(row):\n",
    "    row = [lmtzr.lemmatize(token) for token in row]\n",
    "    row = ' '.join(row) # this is the final step of our guided walkthrough, so I have re-joined the tweets into single documents instead of lists\n",
    "    return row\n",
    "\n",
    "lemmatized = lambda x: lemmatize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8579b56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>house dem aide didnt even see comeys letter ja...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flynn hillary clinton big woman campus breitba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>truth might get fired consortiumnewscom</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15 civilian killed single u airstrike identifi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iranian woman jailed fictional unpublished sto...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature label\n",
       "0  house dem aide didnt even see comeys letter ja...     1\n",
       "1  flynn hillary clinton big woman campus breitba...     0\n",
       "2            truth might get fired consortiumnewscom     1\n",
       "3  15 civilian killed single u airstrike identifi...     1\n",
       "4  iranian woman jailed fictional unpublished sto...     1"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('omw-1.4')\n",
    "\n",
    "# apply the lemmatization function on the train data\n",
    "\n",
    "train_df_updated.loc[:, 'feature'] = train_df_updated['feature'].apply(lemmatized)\n",
    "train_df_updated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bdf9a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import *\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stemming(row):\n",
    "    row = row.split()\n",
    "    row = [stemmer.stem(token) for token in row]\n",
    "    row = ' '.join(row) # this is the final step of our guided walkthrough, so I have re-joined the tweets into single documents instead of lists\n",
    "    return row\n",
    "\n",
    "stemmed = lambda x: stemming(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d4925a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hous dem aid didnt even see comey letter jason...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flynn hillari clinton big woman campu breitbar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>truth might get fire consortiumnewscom</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15 civilian kill singl u airstrik identifi jes...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iranian woman jail fiction unpublish stori wom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature label\n",
       "0  hous dem aid didnt even see comey letter jason...     1\n",
       "1  flynn hillari clinton big woman campu breitbar...     0\n",
       "2             truth might get fire consortiumnewscom     1\n",
       "3  15 civilian kill singl u airstrik identifi jes...     1\n",
       "4  iranian woman jail fiction unpublish stori wom...     1"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply stemming function on the train data\n",
    "\n",
    "train_df_updated.loc[:, 'feature'] = train_df_updated['feature'].apply(stemmed)\n",
    "train_df_updated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4911996f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18285,)\n",
      "(18285,)\n",
      "(18285, 18207)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "\n",
    "# Create a CountVectorizer object to extract features from the text data\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Extract features from the text data and the labels\n",
    "X_train = train_df_updated['feature'].values\n",
    "y_train = train_df_updated['label'].values\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "print(y_train.shape)\n",
    "\n",
    "# fit the model on the train input data\n",
    "\n",
    "X_train_counts = vectorizer.fit_transform(X_train)\n",
    "\n",
    "print(X_train_counts.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2e1440ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.48475270173104\n"
     ]
    }
   ],
   "source": [
    "# Run the NB classifier using cross validation\n",
    "\n",
    "\n",
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "#Create a Naive Bayes Gaussian Classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "#Train the model using the training sets\n",
    "gnb.fit(X_train_counts.toarray(), y_train)\n",
    "\n",
    "#Predict the response for test dataset generated\n",
    "#y_pred = gnb.predict(X_test_counts.toarray())\n",
    "\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "# Evaluate the classifier using 5-fold cross-validation\n",
    "scores = cross_val_score(gnb, X_train_counts.toarray(), y_train, cv=k_fold)\n",
    "\n",
    "# Report the accuracy\n",
    "print('Accuracy:', scores.mean()*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bcac7ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.48475270173104\n"
     ]
    }
   ],
   "source": [
    "# Report Accuracy\n",
    "print('Accuracy:', scores.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "60f6dd03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20800</td>\n",
       "      <td>Specter of Trump Loosens Tongues, if Not Purse...</td>\n",
       "      <td>David Streitfeld</td>\n",
       "      <td>PALO ALTO, Calif.  —   After years of scorning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20801</td>\n",
       "      <td>Russian warships ready to strike terrorists ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Russian warships ready to strike terrorists ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20802</td>\n",
       "      <td>#NoDAPL: Native American Leaders Vow to Stay A...</td>\n",
       "      <td>Common Dreams</td>\n",
       "      <td>Videos #NoDAPL: Native American Leaders Vow to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20803</td>\n",
       "      <td>Tim Tebow Will Attempt Another Comeback, This ...</td>\n",
       "      <td>Daniel Victor</td>\n",
       "      <td>If at first you don’t succeed, try a different...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20804</td>\n",
       "      <td>Keiser Report: Meme Wars (E995)</td>\n",
       "      <td>Truth Broadcast Network</td>\n",
       "      <td>42 mins ago 1 Views 0 Comments 0 Likes 'For th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20805</td>\n",
       "      <td>Trump is USA's antique hero. Clinton will be n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trump is USA's antique hero. Clinton will be n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20806</td>\n",
       "      <td>Pelosi Calls for FBI Investigation to Find Out...</td>\n",
       "      <td>Pam Key</td>\n",
       "      <td>Sunday on NBC’s “Meet the Press,” House Minori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20807</td>\n",
       "      <td>Weekly Featured Profile – Randy Shannon</td>\n",
       "      <td>Trevor Loudon</td>\n",
       "      <td>You are here: Home / *Articles of the Bound* /...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20808</td>\n",
       "      <td>Urban Population Booms Will Make Climate Chang...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Urban Population Booms Will Make Climate Chang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20809</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cognitive dissident</td>\n",
       "      <td>don't we have the receipt?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title  \\\n",
       "0  20800  Specter of Trump Loosens Tongues, if Not Purse...   \n",
       "1  20801  Russian warships ready to strike terrorists ne...   \n",
       "2  20802  #NoDAPL: Native American Leaders Vow to Stay A...   \n",
       "3  20803  Tim Tebow Will Attempt Another Comeback, This ...   \n",
       "4  20804                    Keiser Report: Meme Wars (E995)   \n",
       "5  20805  Trump is USA's antique hero. Clinton will be n...   \n",
       "6  20806  Pelosi Calls for FBI Investigation to Find Out...   \n",
       "7  20807            Weekly Featured Profile – Randy Shannon   \n",
       "8  20808  Urban Population Booms Will Make Climate Chang...   \n",
       "9  20809                                                NaN   \n",
       "\n",
       "                    author                                               text  \n",
       "0         David Streitfeld  PALO ALTO, Calif.  —   After years of scorning...  \n",
       "1                      NaN  Russian warships ready to strike terrorists ne...  \n",
       "2            Common Dreams  Videos #NoDAPL: Native American Leaders Vow to...  \n",
       "3            Daniel Victor  If at first you don’t succeed, try a different...  \n",
       "4  Truth Broadcast Network  42 mins ago 1 Views 0 Comments 0 Likes 'For th...  \n",
       "5                      NaN  Trump is USA's antique hero. Clinton will be n...  \n",
       "6                  Pam Key  Sunday on NBC’s “Meet the Press,” House Minori...  \n",
       "7            Trevor Loudon  You are here: Home / *Articles of the Bound* /...  \n",
       "8                      NaN  Urban Population Booms Will Make Climate Chang...  \n",
       "9      cognitive dissident                         don't we have the receipt?  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the classifer on the test data.\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_csv('test.csv', dtype='str')\n",
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8cb689",
   "metadata": {},
   "source": [
    "## Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c7c0ac7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id          0\n",
      "title     122\n",
      "author    503\n",
      "text        7\n",
      "dtype: int64\n",
      "id        0\n",
      "title     0\n",
      "author    0\n",
      "text      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Specter of Trump Loosens Tongues, if Not Purse...</td>\n",
       "      <td>David Streitfeld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#NoDAPL: Native American Leaders Vow to Stay A...</td>\n",
       "      <td>Common Dreams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tim Tebow Will Attempt Another Comeback, This ...</td>\n",
       "      <td>Daniel Victor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Keiser Report: Meme Wars (E995)</td>\n",
       "      <td>Truth Broadcast Network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pelosi Calls for FBI Investigation to Find Out...</td>\n",
       "      <td>Pam Key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Weekly Featured Profile – Randy Shannon</td>\n",
       "      <td>Trevor Loudon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>184 U.S. generals and admirals endorse Trump f...</td>\n",
       "      <td>Dr. Eowyn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>“Working Class Hero” by John Brennon</td>\n",
       "      <td>Doug Diamond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The Rise of Mandatory Vaccinations Means the E...</td>\n",
       "      <td>Shaun Bradley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Communists Terrorize Small Business</td>\n",
       "      <td>Steve Watson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title                   author\n",
       "0   Specter of Trump Loosens Tongues, if Not Purse...         David Streitfeld\n",
       "2   #NoDAPL: Native American Leaders Vow to Stay A...            Common Dreams\n",
       "3   Tim Tebow Will Attempt Another Comeback, This ...            Daniel Victor\n",
       "4                     Keiser Report: Meme Wars (E995)  Truth Broadcast Network\n",
       "6   Pelosi Calls for FBI Investigation to Find Out...                  Pam Key\n",
       "7             Weekly Featured Profile – Randy Shannon            Trevor Loudon\n",
       "10  184 U.S. generals and admirals endorse Trump f...                Dr. Eowyn\n",
       "11               “Working Class Hero” by John Brennon             Doug Diamond\n",
       "12  The Rise of Mandatory Vaccinations Means the E...            Shaun Bradley\n",
       "13                Communists Terrorize Small Business             Steve Watson"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete rows with na values and selct only relevant columns \n",
    "\n",
    "print(test_df.isnull().sum())\n",
    "\n",
    "test_df = test_df.dropna(axis=0)\n",
    "print(test_df.isnull().sum())\n",
    "\n",
    "test_df = test_df[['title', 'author']]\n",
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6fda49fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Specter of Trump Loosens Tongues, if Not Purse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#NoDAPL: Native American Leaders Vow to Stay A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tim Tebow Will Attempt Another Comeback, This ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Keiser Report: Meme Wars (E995) Truth Broadcas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pelosi Calls for FBI Investigation to Find Out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Weekly Featured Profile – Randy Shannon Trevor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>184 U.S. generals and admirals endorse Trump f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>“Working Class Hero” by John Brennon Doug Diamond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The Rise of Mandatory Vaccinations Means the E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Communists Terrorize Small Business Steve Watson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              feature\n",
       "0   Specter of Trump Loosens Tongues, if Not Purse...\n",
       "2   #NoDAPL: Native American Leaders Vow to Stay A...\n",
       "3   Tim Tebow Will Attempt Another Comeback, This ...\n",
       "4   Keiser Report: Meme Wars (E995) Truth Broadcas...\n",
       "6   Pelosi Calls for FBI Investigation to Find Out...\n",
       "7   Weekly Featured Profile – Randy Shannon Trevor...\n",
       "10  184 U.S. generals and admirals endorse Trump f...\n",
       "11  “Working Class Hero” by John Brennon Doug Diamond\n",
       "12  The Rise of Mandatory Vaccinations Means the E...\n",
       "13   Communists Terrorize Small Business Steve Watson"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the test dataset \n",
    "\n",
    "test_df_updated = pd.DataFrame()\n",
    "test_df_updated['feature'] = test_df['title'] + \" \" + test_df['author']\n",
    "\n",
    "test_df_updated.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b2dc64",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7d025d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>specter trump loosen tongu purs string silicon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nodapl nativ american leader vow stay winter f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tim tebow attempt anoth comeback time basebal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>keiser report meme war e995 truth broadcast ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pelosi call fbi investig find russian donald t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>weekli featur profil randi shannon trevor loudon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>184 u gener admir endors trump commanderinchie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>work class hero john brennon doug diamond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rise mandatori vaccin mean end medic freedom s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>communist terror small busi steve watson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              feature\n",
       "0   specter trump loosen tongu purs string silicon...\n",
       "2   nodapl nativ american leader vow stay winter f...\n",
       "3   tim tebow attempt anoth comeback time basebal ...\n",
       "4   keiser report meme war e995 truth broadcast ne...\n",
       "6   pelosi call fbi investig find russian donald t...\n",
       "7    weekli featur profil randi shannon trevor loudon\n",
       "10  184 u gener admir endors trump commanderinchie...\n",
       "11          work class hero john brennon doug diamond\n",
       "12  rise mandatori vaccin mean end medic freedom s...\n",
       "13           communist terror small busi steve watson"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the clean function created above across each row of the text column in test data\n",
    "test_df_updated.loc[:, 'feature'] = test_df_updated['feature'].apply(clean)\n",
    "\n",
    "# Tokenization of test data\n",
    "test_df_updated.loc[:, 'feature'] = test_df_updated['feature'].apply(tokenized)\n",
    "\n",
    "# Remove stopwords from test data\n",
    "test_df_updated.loc[:, 'feature'] = test_df_updated['feature'].apply(no_stopwords)\n",
    "\n",
    "# Lemmatize test data\n",
    "test_df_updated.loc[:, 'feature'] = test_df_updated['feature'].apply(lemmatized)\n",
    "\n",
    "# Stem test data\n",
    "test_df_updated.loc[:, 'feature'] = test_df_updated['feature'].apply(stemmed)\n",
    "\n",
    "test_df_updated.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4076e76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4575,)\n",
      "(4575, 18207)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>Predicted_Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>specter trump loosen tongu purs string silicon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nodapl nativ american leader vow stay winter f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tim tebow attempt anoth comeback time basebal ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>keiser report meme war e995 truth broadcast ne...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pelosi call fbi investig find russian donald t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature Predicted_Labels\n",
       "0  specter trump loosen tongu purs string silicon...                1\n",
       "2  nodapl nativ american leader vow stay winter f...                1\n",
       "3  tim tebow attempt anoth comeback time basebal ...                0\n",
       "4  keiser report meme war e995 truth broadcast ne...                1\n",
       "6  pelosi call fbi investig find russian donald t...                0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a CountVectorizer object to extract features from the text data\n",
    "\n",
    "# Extract features from the text data and the labels\n",
    "X_test = test_df_updated['feature'].values\n",
    "\n",
    "print(X_test.shape)\n",
    "\n",
    "X_test_counts = vectorizer.transform(X_test)\n",
    "\n",
    "print(X_test_counts.shape)\n",
    "\n",
    "#Predict the response for test dataset that we generated\n",
    "y_pred = gnb.predict(X_test_counts.toarray())\n",
    "\n",
    "test_df_updated['Predicted_Labels'] = y_pred\n",
    "\n",
    "test_df_updated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c12021",
   "metadata": {},
   "source": [
    "## How could you improve your accuracy?\n",
    "While the normal Naive Bayes method is straightforward and efficient, there are more complex variations such as Tree-Augmented Naive Bayes and Semi-Naive Bayes that can increase model performance in some instances.\n",
    "\n",
    "The feature used as input strongly influences the effectiveness of a Naive Bayes model. Precise feature engineering can dramatically enhance model accuracy. This entails picking the most important and useful featuress and appropriately encoding them. Moreover, it is important to get rid of redundant features because high correlation between features adversely affects the accuracy of the model.\n",
    "\n",
    "Another technique to improve the model is to use Naive Bayes in combination with ensemnbling techniques such as bagging and boosting which can help with reducing the the variance and bias in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958307af",
   "metadata": {},
   "source": [
    "## Discussion Questions\n",
    "\n",
    "1. Why is the term \"fake news\" insufficient and problematic as it is commonly applied to the analysis of misinformation? It may help to distinguish between misinformation, disinformation, and propaganda. It may also be useful to trace back how \"fake news\" has been used politically in the US. \n",
    "\n",
    "As it is frequently used to analyze misinformation, the phrase \"fake news\" is inadequate and troublesome since it imprecise. Many a times, especially in political situations, true stories are claimed as false and legitimate sources are discredited. Although the term make the distinguishing process faster, it would give inaccurate results because of how loosely the term is used by the media and the general public.\n",
    "\n",
    "2. Why is it difficult to classify misinformation? What makes something misinformation in the first place? How do people get around being flagged as misinfo? Is it always as binary as \"true\" or \"false\"? \n",
    "\n",
    "Misinformation is difficult to categorize since it can be complex and nuanced. People can purposely conceal the truth for their advantage. Moreover, information spreads very fast, and it is really hard to identify the source of it especially when it is spread by word of mouth. Nobody really bothers to confirm the legitimacy of the information before spreading it. Misinformation is not always binary, true or false. It could be partially true at times.\n",
    "\n",
    "3. Beyond using ML, what domain expertise and stakeholder analysis would be useful for identifying and combatting misinformation? \n",
    "\n",
    "Detecting and combating disinformation necessitates domain knowledge and stakeholder analysis from a variety of professions, including journalism, social media, psychology, and law. Domain specialists can assist in identifying the origins and forms of disinformation, as well as developing ways to address it. Analysis of body language, for instance could be one way of determing whether a person is lying or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f6d927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
